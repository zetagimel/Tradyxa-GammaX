name: Initial Setup (Run Once)

# This workflow should be run ONCE manually to generate all 503 CSVs
# After that, daily_update.yml will append new data incrementally
# NOTE: This may need to be run 2-3 times if it times out on first run

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  initial-setup:
    name: Generate all CSVs from 2005 + Train Models
    runs-on: ubuntu-latest
    timeout-minutes: 90  # Increased from 60 to 90 minutes
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/requirements.txt
      
      - name: Fetch tickers list
        run: python scripts/fetch_tickers.py
      
      # STEP 1: Generate all 503 CSVs from 2005
      # This step is resumable - if CSVs exist, it skips them
      - name: Fetch all 503 stocks (from 2005 to today)
        run: |
          echo "üìä Fetching historical data for 503 tickers from 2005..."
          echo "Note: Existing CSVs will be updated, not re-fetched"
          python scripts/tradyxa_pipeline.py \
            --mode batch_run \
            --tickers-file scripts/nifty500.txt \
            --max-workers 3 \
            --use-yf
        timeout-minutes: 75
      
      # STEP 2: Train ML models on the fresh data
      - name: Train regime classification model
        run: python scripts/train_regime_classifier.py
        continue-on-error: true  # Don't fail if training has issues
      
      - name: Train slippage forecasting models
        run: python scripts/train_slippage_quantile.py
        continue-on-error: true
      
      # STEP 3: Create friendly name copies for indices (NIFTY.json, BANKNIFTY.json)
      - name: Create index friendly name copies
        run: python scripts/create_index_copies.py
        continue-on-error: true
      
      # STEP 4: Apply predictions to all JSONs
      - name: Apply ML predictions to all stocks
        run: python scripts/apply_models.py
        continue-on-error: true
      
      # STEP 5: Fetch live spot prices
      - name: Fetch live spot prices
        run: python scripts/fetch_spot_prices.py
        continue-on-error: true
      
      # STEP 5: Commit everything (ALWAYS RUN - even if previous steps had errors)
      - name: Commit and push all data
        if: always()  # This ensures push happens even if some steps failed
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"
          
          # Show what files were generated
          echo "Generated files:"
          ls -la public/data/raw/*.csv 2>/dev/null | wc -l || echo "0 CSVs"
          ls -la public/data/ticker/*.json 2>/dev/null | wc -l || echo "0 JSONs"
          
          # Add ALL generated files (CSVs, JSONs, models)
          git add -A
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "üöÄ Initial setup: CSVs + trained models [skip ci]"
            
            # Pull latest and push
            git pull origin main --no-rebase --allow-unrelated-histories || true
            git push origin main
            echo "‚úÖ Pushed successfully!"
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Summary
        if: always()
        run: |
          echo "‚úÖ Initial setup completed!"
          echo "üìä CSVs in repo: $(ls public/data/raw/*.csv 2>/dev/null | wc -l || echo 0)"
          echo "üìÑ JSONs in repo: $(ls public/data/ticker/*.json 2>/dev/null | wc -l || echo 0)"
          echo ""
          echo "‚è≠Ô∏è Next steps:"
          echo "   - If not all 503 CSVs generated, run this workflow again"
          echo "   - Daily updates will now append new OHLCV automatically"
          echo "   - Weekly training will retrain models"
